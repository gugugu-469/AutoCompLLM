{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import jsonlines\n",
    "from collections import defaultdict\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMeIE\n",
    "# A. c→(h,r)\n",
    "out_name = 'c_to_ht_withtype'\n",
    "inp_prompt = '''Currently, you are a senior expert in information extraction.\n",
    "Your task is to extract all possible subject-object entity pairs from the given text. First, extract possible subject spans, and based on the extracted subject spans and the given text, continue to extract the corresponding object spans. Then, identify the entity types of the subject and object from the given entity type list.\n",
    "The given entity type list is: {entity_list}.\n",
    "The output format for the task is (subject||subject type||object||object type).\n",
    "The given text: \"{text}\"\n",
    "'''\n",
    "oup_prompt = '{answer_text}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_list = [\n",
    "    'train.json',\n",
    "    'test.json',\n",
    "]\n",
    "out_file_list = [\n",
    "    'train.json',\n",
    "    'test.json'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dir = './ori/DrugProt/'\n",
    "out_dir = './drugProt/pipeline拆解'\n",
    "out_dir = os.path.join(out_dir,out_name)\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "with jsonlines.open(os.path.join(read_dir,'schemas.json'),'r') as f:\n",
    "    trip_types_list = [data for data in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_types = sorted(set([data['predicate'] for data in trip_types_list]))\n",
    "ent_type_list = []\n",
    "for data in trip_types_list:\n",
    "    ent_type_list.append(data['subject_type'])\n",
    "    ent_type_list.append(data['object_type'])\n",
    "ent_types = sorted(set(ent_type_list),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "print('out_name:{}'.format(out_name))\n",
    "for data_file,out_file in zip(data_file_list,out_file_list):\n",
    "    read_path = os.path.join(read_dir,data_file)\n",
    "    out_path = os.path.join(out_dir,out_file)\n",
    "    with jsonlines.open(read_path,'r') as f:\n",
    "        datas = [data for data in f]\n",
    "    with jsonlines.open(out_path,'w') as fw:\n",
    "        for data in datas:\n",
    "            inp = inp_prompt.format(relation_list='[\"' +'\",\"'.join(trip_types) + '\"]',entity_list = '[\"' +'\",\"'.join(ent_types)+ '\"]',text=data['text'])\n",
    "            spo_list = [(item['subject'],item['subject_type'],item['object'], item['object_type']) for item in data['spo_list']]\n",
    "            processed_spo_list = []\n",
    "            for spo_item in spo_list:\n",
    "                if spo_item not in processed_spo_list:\n",
    "                    processed_spo_list.append(spo_item)\n",
    "            oup = '\\n'.join(['({}||{}||{}||{})'.format(item[0],item[1],item[2],item[3]) for item in processed_spo_list])\n",
    "            oup = '```\\n' + oup.strip() + '\\n```'\n",
    "            out_data = {\n",
    "                'instruction':inp,\n",
    "                'input':'',\n",
    "                'output':oup,\n",
    "                'text':data['text'],\n",
    "                'spo_list':data['spo_list']\n",
    "            }\n",
    "            fw.write(out_data)\n",
    "end = time.time()\n",
    "print('cost:{}秒'.format(round(end-start, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMeIE\n",
    "# A. c→(r)\n",
    "out_name = 'c_to_r_withtype'\n",
    "inp_prompt = '''Currently, you are a senior expert in relation classification.\n",
    "Your task is to determine the relation type based on the given text from the given relations. The given relation list is: {relation_list}.\n",
    "The output format for the task is (relation type).\n",
    "The given text: \"{text}\"\n",
    "'''\n",
    "oup_prompt = '{answer_text}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_list = [\n",
    "    'train.json',\n",
    "    'test.json',\n",
    "]\n",
    "out_file_list = [\n",
    "    'train.json',\n",
    "    'test.json'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dir = './ori/DrugProt/'\n",
    "out_dir = './drugProt/pipeline拆解'\n",
    "out_dir = os.path.join(out_dir,out_name)\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "with jsonlines.open(os.path.join(read_dir,'schemas.json'),'r') as f:\n",
    "    trip_types_list = [data for data in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_types = sorted(set([data['predicate'] for data in trip_types_list]))\n",
    "ent_type_list = []\n",
    "for data in trip_types_list:\n",
    "    ent_type_list.append(data['subject_type'])\n",
    "    ent_type_list.append(data['object_type'])\n",
    "ent_types = sorted(set(ent_type_list),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "print('out_name:{}'.format(out_name))\n",
    "for data_file,out_file in zip(data_file_list,out_file_list):\n",
    "    read_path = os.path.join(read_dir,data_file)\n",
    "    out_path = os.path.join(out_dir,out_file)\n",
    "    with jsonlines.open(read_path,'r') as f:\n",
    "        datas = [data for data in f]\n",
    "    with jsonlines.open(out_path,'w') as fw:\n",
    "        for data in datas:\n",
    "            inp = inp_prompt.format(relation_list='[\"' +'\",\"'.join(trip_types) + '\"]',entity_list = '[\"' +'\",\"'.join(ent_types)+ '\"]',text=data['text'])\n",
    "            spo_list = []\n",
    "            for item in data['spo_list']:\n",
    "                if item['predicate'] not in spo_list:\n",
    "                    spo_list.append(item['predicate'])\n",
    "            processed_spo_list = []\n",
    "            for spo_item in spo_list:\n",
    "                if spo_item not in processed_spo_list:\n",
    "                    processed_spo_list.append(spo_item)\n",
    "            oup = '\\n'.join(['({})a'.format(item) for item in processed_spo_list])\n",
    "            oup = '```\\n' + oup.strip() + '\\n```'\n",
    "            out_data = {\n",
    "                'instruction':inp,\n",
    "                'input':'',\n",
    "                'output':oup,\n",
    "                'text':data['text'],\n",
    "                'spo_list':data['spo_list']\n",
    "            }\n",
    "            fw.write(out_data)\n",
    "end = time.time()\n",
    "print('cost:{}秒'.format(round(end-start, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMeIE\n",
    "# B. c→(t,r)\n",
    "out_name = 'rc_to_ht_withtype'\n",
    "inp_prompt = '''Currently, you are a senior expert in information extraction.\n",
    "Your task is to extract all possible subject-object entity pairs from the given text and relation type. First, extract possible subject spans, and based on the extracted subject spans and the given text, continue to extract the corresponding object spans. Then, identify the entity types of the subject and object from the given entity type list.\n",
    "The given entity type list is: {entity_list}.\n",
    "The output format for the task is (subject||subject type||object||object type).\n",
    "The given text: \"{text}\"\n",
    "The given relation type: \"{relation}\"\n",
    "'''\n",
    "oup_prompt = '{answer_text}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_list = [\n",
    "    'train.json',\n",
    "    'test.json',\n",
    "]\n",
    "out_file_list = [\n",
    "    'train.json',\n",
    "    'test.json'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dir = './ori/DrugProt/'\n",
    "out_dir = './drugProt/pipeline拆解'\n",
    "out_dir = os.path.join(out_dir,out_name)\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "with jsonlines.open(os.path.join(read_dir,'schemas.json'),'r') as f:\n",
    "    trip_types_list = [data for data in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_types = sorted(set([data['predicate'] for data in trip_types_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "print('out_name:{}'.format(out_name))\n",
    "for data_file,out_file in zip(data_file_list,out_file_list):\n",
    "    read_path = os.path.join(read_dir,data_file)\n",
    "    out_path = os.path.join(out_dir,out_file)\n",
    "    with jsonlines.open(read_path,'r') as f:\n",
    "        datas = [data for data in f]\n",
    "    with jsonlines.open(out_path,'w') as fw:\n",
    "        for data in datas:\n",
    "            relation_to_ht = defaultdict(list)\n",
    "            for spo_item in data['spo_list']:\n",
    "                sub = spo_item['subject']\n",
    "                sub_type = spo_item['subject_type']\n",
    "                predicate = spo_item['predicate']\n",
    "                obj = spo_item['object']\n",
    "                obj_type = spo_item['object_type']\n",
    "                relation_to_ht[predicate].append((sub, sub_type, obj, obj_type))\n",
    "            for predicate in relation_to_ht.keys():\n",
    "                spo_list = relation_to_ht[predicate]\n",
    "                inp = inp_prompt.format(relation_list='[\"' +'\",\"'.join(trip_types) + '\"]',entity_list = '[\"' +'\",\"'.join(ent_types)+ '\"]',text=data['text'], relation = predicate)\n",
    "                oup = '\\n'.join(['({}||{}||{}||{})'.format(item[0],item[1],item[2],item[3]) for item in spo_list])\n",
    "                oup = '```\\n' + oup.strip() + '\\n```'\n",
    "                out_data = {\n",
    "                    'instruction':inp,\n",
    "                    'input':'',\n",
    "                    'output':oup,\n",
    "                    'text':data['text'],\n",
    "                    'spo_list':data['spo_list']\n",
    "                }\n",
    "                fw.write(out_data)\n",
    "end = time.time()\n",
    "print('cost:{}秒'.format(round(end-start, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMeIE\n",
    "# C. h[s1]c→(t,r)\n",
    "out_name = 'htc_to_r_withtype'\n",
    "inp_prompt = '''Currently, you are a senior expert in relation classification.\n",
    "Your task is to determine possible relations from the given relation list based on the given text, subject-object entity pairs, and their types.\n",
    "The given relation list is: {relation_list}.\n",
    "The input format for entity pairs is (subject||subject type||object||object type).\n",
    "The output format for the task is (relation type).\n",
    "The given text: \"{text}\"\n",
    "The given subject-object entity pair: \"{head_tail}\"\n",
    "'''\n",
    "oup_prompt = '{answer_text}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_list = [\n",
    "    'train.json',\n",
    "    'test.json',\n",
    "]\n",
    "out_file_list = [\n",
    "    'train.json',\n",
    "    'test.json'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dir = './ori/DrugProt/'\n",
    "out_dir = './drugProt/pipeline拆解'\n",
    "out_dir = os.path.join(out_dir,out_name)\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "with jsonlines.open(os.path.join(read_dir,'schemas.json'),'r') as f:\n",
    "    trip_types_list = [data for data in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_types = sorted(set([data['predicate'] for data in trip_types_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "print('out_name:{}'.format(out_name))\n",
    "for data_file,out_file in zip(data_file_list,out_file_list):\n",
    "    read_path = os.path.join(read_dir,data_file)\n",
    "    out_path = os.path.join(out_dir,out_file)\n",
    "    with jsonlines.open(read_path,'r') as f:\n",
    "        datas = [data for data in f]\n",
    "    with jsonlines.open(out_path,'w') as fw:\n",
    "        for data in datas:\n",
    "            ht_to_relation = defaultdict(list)\n",
    "            for spo_item in data['spo_list']:\n",
    "                sub = spo_item['subject']\n",
    "                sub_type = spo_item['subject_type']\n",
    "                predicate = spo_item['predicate']\n",
    "                obj = spo_item['object']\n",
    "                obj_type = spo_item['object_type']\n",
    "                ht_item = (sub, sub_type, obj, obj_type)\n",
    "                ht_to_relation[ht_item].append(predicate)\n",
    "            for ht_item in ht_to_relation.keys():\n",
    "                predicate = ht_to_relation[ht_item]\n",
    "                ht_item_str = '({}||{}||{}||{})'.format(ht_item[0], ht_item[1], ht_item[2], ht_item[3])\n",
    "                inp = inp_prompt.format(relation_list='[\"' +'\",\"'.join(trip_types) + '\"]',entity_list = '[\"' +'\",\"'.join(ent_types)+ '\"]',text=data['text'], head_tail = ht_item_str)\n",
    "                oup = '\\n'.join(['({})'.format(item) for item in predicate])\n",
    "                oup = '```\\n' + oup.strip() + '\\n```'\n",
    "                out_data = {\n",
    "                    'instruction':inp,\n",
    "                    'input':'',\n",
    "                    'output':oup,\n",
    "                    'text':data['text'],\n",
    "                    'spo_list':data['spo_list']\n",
    "                }\n",
    "                fw.write(out_data)\n",
    "\n",
    "end = time.time()\n",
    "print('cost:{}秒'.format(round(end-start, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_end = time.time()\n",
    "all_end-all_start"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_factory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
